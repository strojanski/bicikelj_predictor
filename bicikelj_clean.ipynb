{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/bicikelj_train.csv\")\n",
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "\n",
    "test = pd.read_csv(\"data/bicikelj_test.csv\")\n",
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_processed.csv\")\n",
    "test = pd.read_csv(\"data/test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract new features\n",
    "def get_time_based_features(timestamp):\n",
    "    # From datetime64 get month, day, hour, dayOfWeek and isHoliday\n",
    "    timestamp = np.datetime64(timestamp)\n",
    "    dt_python = timestamp.astype(datetime.datetime)\n",
    "\n",
    "    # Extract month, day, hour, and day_of_week\n",
    "    month = dt_python.month\n",
    "    day = dt_python.day\n",
    "    hour = dt_python.hour\n",
    "    minute = dt_python.minute\n",
    "    day_of_week = dt_python.weekday()\n",
    "\n",
    "    # Check for holidays\n",
    "    is_holiday = 0\n",
    "    if dt_python.month == 8 and dt_python.day in [15, 17]:\n",
    "        is_holiday = 1\n",
    "    elif dt_python.month == 9 and dt_python.day in [15, 23]:\n",
    "        is_holiday = 1\n",
    "        \n",
    "        \n",
    "    is_weekend = 0\n",
    "    if dt_python.weekday() in [5, 6]:\n",
    "        is_weekend = 1\n",
    "   \n",
    "    is_night = 0\n",
    "    if hour < 6 or hour > 22:\n",
    "        is_night = 1\n",
    "        \n",
    "    school_holiday = 0\n",
    "    if 6 <= month <= 8:\n",
    "        school_holiday = 1\n",
    "   \n",
    "    return month, day, hour, minute, day_of_week, is_holiday, is_weekend, is_night, school_holiday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of stations\n",
    "stations = []\n",
    "for i in range(1, 84):\n",
    "    stations.append(train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for station in stations:\n",
    "    to_drop.append(f\"{station}_150min\")\n",
    "train = train.drop(to_drop, axis=1)\n",
    "test = test.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_smaller_row(df, timestamp, hour_offset, thresh=15):\n",
    "    print(timestamp)\n",
    "    target_timestamp = pd.to_datetime(timestamp) - pd.DateOffset(hours=hour_offset)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    \n",
    "    smaller_rows = df[(pd.to_datetime(df[\"timestamp\"]) <= target_timestamp) & (df[\"timestamp\"] > target_timestamp - datetime.timedelta(minutes=thresh))]\n",
    "    if smaller_rows.empty:\n",
    "        # Exclude from training\n",
    "        return None\n",
    "    closest_index = np.argmin(np.abs(target_timestamp - pd.to_datetime(smaller_rows[\"timestamp\"])))\n",
    "    print(smaller_rows[\"timestamp\"], closest_index)\n",
    "    closest_row = smaller_rows.iloc[closest_index]\n",
    "    \n",
    "    return closest_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest(df, timestamp, minute_offset=60, thresh=15):\n",
    "    target_ts = pd.to_datetime(timestamp) - pd.DateOffset(minutes=minute_offset) \n",
    "    data = df.copy()\n",
    "    data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "    data = data[(data[\"timestamp\"] <= target_ts + pd.DateOffset(minutes=5)) & (data[\"timestamp\"] > target_ts - pd.DateOffset(minutes=thresh))]\n",
    "    if len(data) == 0: \n",
    "        return None\n",
    "    \n",
    "    # print(target_ts, \"\\n\", data[\"timestamp\"])\n",
    "    closest_index = np.argmin(np.abs(target_ts - pd.to_datetime(data[\"timestamp\"])))\n",
    "    # print(\"Closest\", data.iloc[closest_index][\"timestamp\"])\n",
    "    return data.iloc[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest(train, \"2022-08-02 14:10:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6906, 377)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for station in stations:\n",
    "#     train[f\"{station}_1hr\"] = [None for _ in range(train.shape[0])]\n",
    "#     train[f\"{station}_2hr\"] = [None for _ in range(train.shape[0])]\n",
    "    \n",
    "# train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 rows\n",
      "Processed 10 rows\n",
      "Processed 20 rows\n",
      "Processed 30 rows\n"
     ]
    }
   ],
   "source": [
    " # offset_df = pd.DataFrame(columns=[f\"{station}_1hr\" for station in stations] + [f\"{station}_2hr\" for station in stations])\n",
    "\n",
    "for i, timestamp in enumerate(test[\"timestamp\"]):\n",
    "#     # row_1hr = closest(train, timestamp, 1)\n",
    "#     # row_2hr = closest(train, timestamp, 2)\n",
    "    row_150 = closest(train, timestamp, 150)\n",
    "    \n",
    "        \n",
    "    if row_150 is not None:\n",
    "        # offset_df.append(row_1hr[stations], ignore_index=True)\n",
    "        test.loc[i, [f\"{station}_150min\" for station in stations]] = row_150[stations].values\n",
    "    \n",
    "#     # if row_1hr is not None:\n",
    "#     #     # offset_df.append(row_1hr[stations], ignore_index=True)\n",
    "#     #     train.loc[i, [f\"{station}_1hr\" for station in stations]] = row_1hr[stations].values\n",
    "        \n",
    "# #     if row_2hr is not None:\n",
    "# #         train.loc[i, [f\"{station}_2hr\" for station in stations]] = row_2hr[stations].values\n",
    "    \n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i} rows\")\n",
    "    \n",
    "# # Remove all rows with None\n",
    "# train = train.dropna()\n",
    "#     train[f\"{station}_1hr\"] = train.columns.apply(lambda station: find_closest_smaller_row(train, time, 1, station))\n",
    "#     train[f\"{station}_2hr\"] = train[\"timestamp\"].apply(lambda time: find_closest_smaller_row(train, time, 2, station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'PREŠERNOV TRG-PETKOVŠKOVO NABREŽJE',\n",
       "       'POGAČARJEV TRG-TRŽNICA', 'KONGRESNI TRG-ŠUBIČEVA ULICA',\n",
       "       'CANKARJEVA UL.-NAMA', 'BREG', 'GRUDNOVO NABREŽJE-KARLOVŠKA C.',\n",
       "       'MIKLOŠIČEV PARK', 'BAVARSKI DVOR', 'TRG OF-KOLODVORSKA UL.',\n",
       "       ...\n",
       "       'POVŠETOVA - KAJUHOVA_150min', 'SOSESKA NOVO BRDO_150min',\n",
       "       'TEHNOLOŠKI PARK_150min', 'VOJKOVA - GASILSKA BRIGADA_150min',\n",
       "       'GERBIČEVA - ŠPORTNI PARK SVOBODA_150min',\n",
       "       'DOLENJSKA C. - STRELIŠČE_150min', 'ROŠKA - STRELIŠKA_150min',\n",
       "       'LEK - VEROVŠKOVA_150min', 'VOKA - SLOVENČEVA_150min',\n",
       "       'SUPERNOVA LJUBLJANA - RUDNIK_150min'],\n",
       "      dtype='object', length=460)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, timestamp in enumerate(test[\"timestamp\"]):\n",
    "#     row_1hr = closest(train, timestamp, 90)\n",
    "# #     row_2hr = closest(train, timestamp, 2)\n",
    "    \n",
    "#     if row_1hr is not None:\n",
    "# #         # offset_df.append(row_1hr[stations], ignore_index=True)\n",
    "#         test.loc[i, [f\"{station}_90min\" for station in stations]] = row_1hr[stations].values\n",
    "        \n",
    "#     if row_2hr is not None:\n",
    "#         test.loc[i, [f\"{station}_2hr\" for station in stations]] = row_2hr[stations].values\n",
    "    \n",
    "    \n",
    "#     if i % 100 == 0:\n",
    "#         print(f\"Processed {i} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.to_csv(\"data/enriched_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"data/test_train.csv\")\n",
    "# test = pd.read_csv(\"data/enriched_test.csv\")\n",
    "# train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.to_csv(\"data/test_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train\n",
    "# d = pd.read_csv(\"data/test_train.csv\")\n",
    "ix = 12\n",
    "for station in stations:\n",
    "    if d.iloc[ix][station] - d.iloc[ix + 18][f'{station}_90min'] != 0:\n",
    "        print(f\"{station} time: {d.iloc[ix]['timestamp']} - {d.iloc[ix + 12]['timestamp']}: n-bikes vs n_bikes_90min {d.iloc[ix][station]} {d.iloc[ix + 12][f'{station}_90min']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'PREŠERNOV TRG-PETKOVŠKOVO NABREŽJE',\n",
       "       'POGAČARJEV TRG-TRŽNICA', 'KONGRESNI TRG-ŠUBIČEVA ULICA',\n",
       "       'CANKARJEVA UL.-NAMA', 'BREG', 'GRUDNOVO NABREŽJE-KARLOVŠKA C.',\n",
       "       'MIKLOŠIČEV PARK', 'BAVARSKI DVOR', 'TRG OF-KOLODVORSKA UL.',\n",
       "       ...\n",
       "       'SOSESKA NOVO BRDO_90min', 'TEHNOLOŠKI PARK_90min',\n",
       "       'VOJKOVA - GASILSKA BRIGADA_90min',\n",
       "       'GERBIČEVA - ŠPORTNI PARK SVOBODA_90min',\n",
       "       'DOLENJSKA C. - STRELIŠČE_90min', 'ROŠKA - STRELIŠKA_90min',\n",
       "       'LEK - VEROVŠKOVA_90min', 'VOKA - SLOVENČEVA_90min',\n",
       "       'SUPERNOVA LJUBLJANA - RUDNIK_90min', 'feelslike'],\n",
       "      dtype='object', length=377)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new features to train\n",
    "# train['month'], train['day'], train['hour'], train['minute'], train['day_of_week'], train['is_holiday'], train['is_weekend'], train['is_night'], train['school_holiday'] = zip(*train['timestamp'].map(get_time_based_features))\n",
    "# test['month'], test['day'], test['hour'], test['minute'], test['day_of_week'], test['is_holiday'], test['is_weekend'], test['is_night'], test['school_holiday'] = zip(*test['timestamp'].map(get_time_based_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>postaja</th>\n",
       "      <th>geo-visina</th>\n",
       "      <th>geo-sirina</th>\n",
       "      <th>total_space</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREŠERNOV TRG-PETKOVŠKOVO NABREŽJE</td>\n",
       "      <td>46.051367</td>\n",
       "      <td>14.506542</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POGAČARJEV TRG-TRŽNICA</td>\n",
       "      <td>46.051093</td>\n",
       "      <td>14.507186</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KONGRESNI TRG-ŠUBIČEVA ULICA</td>\n",
       "      <td>46.050388</td>\n",
       "      <td>14.504623</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CANKARJEVA UL.-NAMA</td>\n",
       "      <td>46.052431</td>\n",
       "      <td>14.503257</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BREG</td>\n",
       "      <td>46.046498</td>\n",
       "      <td>14.505148</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              postaja  geo-visina  geo-sirina  total_space\n",
       "0  PREŠERNOV TRG-PETKOVŠKOVO NABREŽJE   46.051367   14.506542           20\n",
       "1              POGAČARJEV TRG-TRŽNICA   46.051093   14.507186           18\n",
       "2        KONGRESNI TRG-ŠUBIČEVA ULICA   46.050388   14.504623           20\n",
       "3                 CANKARJEVA UL.-NAMA   46.052431   14.503257           26\n",
       "4                                BREG   46.046498   14.505148           20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_meta = pd.read_csv(\"data/bicikelj_metadata.csv\", sep=\"\\t\")\n",
    "stations_meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode days of week and hours\n",
    "days_of_week = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "\n",
    "# for i, day in enumerate(days_of_week):\n",
    "#     train[day] = (train[\"day_of_week\"] == i).astype(int) \n",
    "#     test[day] = (test[\"day_of_week\"] == i).astype(int)\n",
    "\n",
    "\n",
    "# hours = [i for i in range(24)]\n",
    "# for i in hours:\n",
    "#     train[f\"hour_{i}\"] = (train[\"hour\"] == i).astype(int)\n",
    "#     test[f\"hour_{i}\"] = (test[\"hour\"] == i).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/train_processed.csv\", index=False)\n",
    "test.to_csv(\"data/test_processed.csv\", index=False)\n",
    "\n",
    "train = pd.read_csv(\"data/train_processed.csv\")\n",
    "test = pd.read_csv(\"data/test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of stations\n",
    "stations = []\n",
    "for i in range(1, 84):\n",
    "    stations.append(train.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_station_dataframes = {}\n",
    "test_station_dataframes = {}\n",
    "\n",
    "for station in stations:\n",
    "            \n",
    "    for n in range(2):\n",
    "        if n == 0:\n",
    "            dataframe = train\n",
    "        else:\n",
    "            dataframe = test\n",
    "        station_df = pd.DataFrame({\n",
    "            \"timestamp\": dataframe[\"timestamp\"].values,\n",
    "            \"n_bikes\": dataframe[station].values,\n",
    "            \"month\": dataframe[\"month\"].values,\n",
    "            \"day\": dataframe[\"day\"].values,\n",
    "            \"hour\": dataframe[\"hour\"].values,\n",
    "            \"minute\": dataframe[\"minute\"].values,\n",
    "            \"day_of_week\": dataframe[\"day_of_week\"].values,\n",
    "            \"is_holiday\": dataframe[\"is_holiday\"].values,\n",
    "            \"is_weekend\": dataframe[\"is_weekend\"].values,\n",
    "            \"is_night\": dataframe[\"is_night\"].values,\n",
    "            \"school_holiday\": dataframe[\"school_holiday\"].values,\n",
    "            \"n_bikes_1hr\": dataframe[f\"{station}_1hr\"].values,\n",
    "            \"n_bikes_2hr\": dataframe[f\"{station}_2hr\"].values,\n",
    "            \"n_bikes_90min\": dataframe[f\"{station}_90min\"].values,\n",
    "            \"rain\": dataframe[\"rain\"].values,\n",
    "            \"rain_condition\": dataframe[\"rain_condition\"].values,\n",
    "            \"feelslike\": dataframe[\"feelslike\"].values,\n",
    "            \"temp\": dataframe[\"temp\"].values\n",
    "        })\n",
    "        \n",
    "        days_of_week = [\"monday\", \"tuesday\", \"wednesday\", \"thursday\", \"friday\", \"saturday\", \"sunday\"]\n",
    "\n",
    "        for i, day in enumerate(days_of_week):\n",
    "            station_df[day] = dataframe[day].values\n",
    "\n",
    "\n",
    "        hours = [i for i in range(24)]\n",
    "        for i in hours:\n",
    "            station_df[f\"hour_{i}\"] = dataframe[f\"hour_{i}\"].values   \n",
    "            \n",
    "        if n == 0:    \n",
    "            train_station_dataframes[station] = station_df\n",
    "        else: test_station_dataframes[station] = station_df\n",
    "        \n",
    "        # station = station.replace(\"/\", \"_\")\n",
    "        # if n == 0:\n",
    "        #     station_df.to_csv(f\"data/stations/{station}_train.csv\", index=False)\n",
    "        # else:\n",
    "        #     station_df.to_csv(f\"data/stations/{station}_test.csv\", index=False)    \n",
    "    # station_df.to_csv(f\"data/stations/{station}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X_train, X_test, y_train, y_test=None):\n",
    "    # Fit model\n",
    "   # lr = linear_model.Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None, solver=\"auto\", tol=1e-10) \n",
    "    lr = linear_model.Ridge() \n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and score\n",
    "    y_pred = lr.predict(X_test)\n",
    "    \n",
    "    if y_test is not None:\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"MSE: {mse}\")\n",
    "    \n",
    "    return lr, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_test, y_train, y_test=None):\n",
    "    rf = RandomForestRegressor(n_estimators=1000, max_depth=10, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf.predict(X_test)\n",
    "    return rf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_ridge(X_train, X_test, y_train, y_test=None):\n",
    "    # Fit model\n",
    "    kr = KernelRidge(alpha=1, kernel=\"rbf\") \n",
    "    # lr = linear_model.LinearRegression()\n",
    "    kr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and score\n",
    "    y_pred = kr.predict(X_test)\n",
    "    \n",
    "    return kr, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr(X_train, X_test, y_train, y_test=None, kernel=\"rbf\"):\n",
    "    # Fit model\n",
    "    svr = SVR() \n",
    "    # lr = linear_model.LinearRegression()\n",
    "    svr.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and score\n",
    "    y_pred = svr.predict(X_test)\n",
    "    \n",
    "    return svr, y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use train set to get good results first and then use test set on classroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 7.91629484791617\n"
     ]
    }
   ],
   "source": [
    "avg_mse = 0\n",
    "# Perform linear regression on all stations\n",
    "for station in stations:\n",
    "    station_df = train_station_dataframes[station]\n",
    "    \n",
    "    X = station_df.drop([\"timestamp\", \"n_bikes\", \"minute\", \"day_of_week\"], axis=1)\n",
    "    y = station_df[\"n_bikes\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)   \n",
    "        \n",
    "    X_train_1hr = X_train[X_train.index % 2 == 0]\n",
    "    X_train_2hr = X_train[X_train.index % 2 == 1]\n",
    "    \n",
    "    y_train_1hr = y_train[y_train.index % 2 == 0]\n",
    "    y_train_2hr = y_train[y_train.index % 2 == 1]\n",
    "    \n",
    "    X_test_1hr = X_test[X_test.index % 2 == 0]\n",
    "    X_test_2hr = X_test[X_test.index % 2 == 1]\n",
    "    \n",
    "    # No data for 1hr back\n",
    "    X_train_2hr = np.array(X_train_2hr[\"n_bikes_2hr\"]).reshape(-1, 1) \n",
    "    X_test_2hr = np.array(X_test_2hr[\"n_bikes_2hr\"]).reshape(-1, 1)\n",
    "    \n",
    "    lr_1h, y_pred_1h = linear_regression(X_train_1hr, X_test_1hr, y_train_1hr)\n",
    "    lr_2h, y_pred_2h = linear_regression(X_train_2hr, X_test_2hr, y_train_2hr)\n",
    "    \n",
    "    # rf_1h, y_pred_1h = random_forest(X_train_1hr, X_test_1hr, y_train_1hr)\n",
    "    # rf_2h, y_pred_2h = random_forest(X_train_2hr, X_test_2hr, y_train_2hr)\n",
    "    \n",
    "    y_pred = np.empty(len(y_pred_1h) + len(y_pred_2h))\n",
    "    y_pred[::2] = y_pred_1h\n",
    "    # print(y_pred_1h, y_pred_2h)\n",
    "    y_pred[1::2] = y_pred_2h\n",
    "    \n",
    "    avg_mse += mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    y_pred = pd.DataFrame({\"n_bikes\": y_pred})\n",
    "\n",
    "avg_mse /= len(stations)\n",
    "        \n",
    "print(f\"Score: {avg_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'PREŠERNOV TRG-PETKOVŠKOVO NABREŽJE',\n",
       "       'POGAČARJEV TRG-TRŽNICA', 'KONGRESNI TRG-ŠUBIČEVA ULICA',\n",
       "       'CANKARJEVA UL.-NAMA', 'BREG', 'GRUDNOVO NABREŽJE-KARLOVŠKA C.',\n",
       "       'MIKLOŠIČEV PARK', 'BAVARSKI DVOR', 'TRG OF-KOLODVORSKA UL.',\n",
       "       ...\n",
       "       'POVŠETOVA - KAJUHOVA_150min', 'SOSESKA NOVO BRDO_150min',\n",
       "       'TEHNOLOŠKI PARK_150min', 'VOJKOVA - GASILSKA BRIGADA_150min',\n",
       "       'GERBIČEVA - ŠPORTNI PARK SVOBODA_150min',\n",
       "       'DOLENJSKA C. - STRELIŠČE_150min', 'ROŠKA - STRELIŠKA_150min',\n",
       "       'LEK - VEROVŠKOVA_150min', 'VOKA - SLOVENČEVA_150min',\n",
       "       'SUPERNOVA LJUBLJANA - RUDNIK_150min'],\n",
       "      dtype='object', length=460)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20\n",
       "Name: total_space, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_meta.loc[stations_meta[\"postaja\"] == stations[0]][\"total_space\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly = PolynomialFeatures(2, include_bias=False)\n",
    "\n",
    "# test = pd.read_csv(\"data/test_expanded.csv\")\n",
    "output = pd.read_csv(\"data/bicikelj_test.csv\").copy()\n",
    "\n",
    "# Perform linear regression on all stations\n",
    "for station in stations:\n",
    "\n",
    "    station_df = train_station_dataframes[station]\n",
    "    \n",
    "    X_train = station_df.drop([\"timestamp\", \"n_bikes\"], axis=1)\n",
    "    y_train = station_df[\"n_bikes\"]\n",
    "\n",
    "\n",
    "    \n",
    "    X_test = test_station_dataframes[station].drop([\"timestamp\", \"n_bikes\"], axis=1)\n",
    "    \n",
    "    X_train_1hr = X_train[X_train.index % 2 == 0]\n",
    "    X_train_2hr = X_train[X_train.index % 2 == 1]\n",
    "    y_train_1hr = y_train[y_train.index % 2 == 0]\n",
    "    y_train_2hr = y_train[y_train.index % 2 == 1]\n",
    "    X_test_1hr = X_test[X_test.index % 2 == 0]\n",
    "    X_test_2hr = X_test[X_test.index % 2 == 1]\n",
    "    \n",
    "    # No data for 1hr back\n",
    "    X_train_2hr = np.array(X_train_2hr.drop([\"n_bikes_1hr\", \"n_bikes_90min\"], axis=1))\n",
    "    X_test_2hr = np.array(X_test_2hr.drop([\"n_bikes_1hr\", \"n_bikes_90min\"], axis=1))\n",
    "    \n",
    "    # X_train_1hr = poly.fit_transform(X_train_1hr)\n",
    "    # X_test_1hr = poly.fit_transform(X_test_1hr)\n",
    "    \n",
    "    # X_train_2hr = poly.fit_transform(X_train_2hr)\n",
    "    # X_test_2hr = poly.fit_transform(X_test_2hr)\n",
    "    \n",
    "    \n",
    "    lr_1h, y_pred_1h = linear_regression(X_train_1hr, X_test_1hr, y_train_1hr)\n",
    "    lr_2h, y_pred_2h = linear_regression(X_train_2hr, X_test_2hr, y_train_2hr)\n",
    "    \n",
    "    # rf_1h, y_pred_1h = random_forest(X_train_1hr, X_test_1hr, y_train_1hr)\n",
    "    # rf_2h, y_pred_2h = random_forest(X_train_2hr, X_test_2hr, y_train_2hr)\n",
    "    \n",
    "    y_pred = np.empty(len(y_pred_1h) + len(y_pred_2h))\n",
    "    y_pred[::2] = y_pred_1h\n",
    "    # print(y_pred_1h, y_pred_2h)\n",
    "    y_pred[1::2] = y_pred_2h\n",
    "    \n",
    "    y_pred = pd.DataFrame({\"n_bikes\": y_pred})\n",
    "    \n",
    "    # Set values in y_pred to 0 if negative\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    \n",
    "    total_space = stations_meta.loc[stations_meta[\"postaja\"] == station][\"total_space\"].values[0]\n",
    "    y_pred[y_pred > total_space] = total_space\n",
    "    \n",
    "    \n",
    "    # m = lr_1h.coef_.argsort()[::-1]\n",
    "    \n",
    "    # for i in range(len(m)):\n",
    "        \n",
    "    #     print(X_train.columns[m[i]], lr.coef_[m[i]])\n",
    "    output[station] = y_pred\n",
    "    \n",
    "output.to_csv(\"data/output.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_bikes_3hr??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
